# ğŸ““ Databricks Notebook Import Guide

## ğŸ¯ Overview
This repository now contains **proper Databricks notebook format files** that can be directly imported into any Databricks workspace.

## ğŸ“‚ Notebook Structure

### **âœ… Ready-to-Import Notebooks (26 Files)**

#### ğŸ¤– **AgentBricks/** - Core Agent System
```
notebooks_proper_format/AgentBricks/
â”œâ”€â”€ 01_Severity_Classification_Agent_TRUE_AI_HYBRID_FIXED.py
â”œâ”€â”€ 02_Incident_Manager_AgentBricks_TRUE_AI_HYBRID_FIXED.py
â”œâ”€â”€ 03_Network_Ops_Agent_AgentBricks_TRUE_AI_HYBRID_FIXED.py
â”œâ”€â”€ 04_RCA_Agent_AgentBricks_TRUE_AI_HYBRID_FIXED.py
â””â”€â”€ 05_Multi_Agent_Orchestrator_AgentBricks_TRUE_AI_HYBRID_FIXED.py
```

#### ğŸ” **MCP-RAG/** - RAG System
```
notebooks_proper_format/MCP-RAG/
â”œâ”€â”€ RAG_01_Vector_Search_Setup.py
â”œâ”€â”€ RAG_02_Embeddings_Pipeline.py
â”œâ”€â”€ RAG_03_Intelligent_Search_Interface.py
â”œâ”€â”€ RAG_04_End_to_End_Testing.py
â””â”€â”€ RAG_Working_Interface_FIXED.py
```

#### ğŸŒ **Flask_Apps/** - Web Applications
```
notebooks_proper_format/Flask_Apps/
â”œâ”€â”€ deploy_workspace_flask_fixed.py
â”œâ”€â”€ app_flask_working_rag.py
â”œâ”€â”€ app_flask_real_rag.py
â”œâ”€â”€ test_rag_connection_fixed.py
â””â”€â”€ [5 additional Flask components]
```

#### ğŸ“Š **Step-2-MultiAgent/** - Pipeline Components
```
notebooks_proper_format/Step-2-MultiAgent/
â”œâ”€â”€ 01-data-ingestion.py
â”œâ”€â”€ 02-streaming-pipeline.py
â”œâ”€â”€ 03-agent-orchestration.py
â”œâ”€â”€ Lakeview_Dashboard_Setup_CORRECTED.py
â””â”€â”€ [3 additional pipeline components]
```

## ğŸš€ Import Instructions

### **Method 1: Individual File Import** *(Recommended)*
1. **Download Files**: Clone or download this repository
2. **Open Databricks Workspace**
3. **Import Process**:
   ```
   Workspace â†’ Import â†’ File
   Select: notebooks_proper_format/AgentBricks/01_Severity_Classification_Agent_TRUE_AI_HYBRID_FIXED.py
   Click: Import
   ```
4. **Repeat for Each Component**: Import files based on your needs

### **Method 2: Bulk Import**
1. **Download Entire Folder**: `notebooks_proper_format/`
2. **Databricks Workspace**:
   ```
   Workspace â†’ Import â†’ Folder
   Select: notebooks_proper_format folder
   ```
3. **Preserve Structure**: Maintains organized folder hierarchy

### **Method 3: Git Integration** *(Enterprise)*
1. **Databricks Repos**:
   ```
   Workspace â†’ Repos â†’ Add Repo
   URL: https://github.com/somaazure/Network-Fault-Detection-RCA-System-Databricks
   ```
2. **Navigate**: Go to `notebooks_proper_format/` folder
3. **Direct Access**: Use notebooks directly from Git

## ğŸ”§ Post-Import Configuration

### **1. Set Up Databricks Secrets** *(Required)*
```python
# Run in Databricks notebook cell
dbutils.secrets.createScope("default")

# Add your workspace credentials
dbutils.secrets.put("default", "databricks-host", "https://your-workspace.cloud.databricks.com")
dbutils.secrets.put("default", "databricks-token", "your-databricks-token")
```

### **2. Unity Catalog Setup**
```sql
-- Create catalog and schema
CREATE CATALOG IF NOT EXISTS network_fault_detection;
CREATE SCHEMA IF NOT EXISTS network_fault_detection.processed_data;

-- Verify permissions
SHOW GRANTS ON CATALOG network_fault_detection;
```

### **3. Verification Steps**
Run these notebooks in order:
1. âœ… **Agent 01**: Severity Classification
2. âœ… **Agent 02**: Incident Manager
3. âœ… **Agent 03**: Network Operations
4. âœ… **Agent 04**: RCA Analysis
5. âœ… **Agent 05**: Multi-Agent Orchestrator
6. âœ… **RAG System**: Vector Search Setup â†’ Testing

## ğŸ›¡ï¸ Security Features

### **âœ… Secure Configuration Patterns**
All notebooks use environment-safe patterns:
```python
# Secure - uses secrets or environment variables
DATABRICKS_HOST = os.getenv('DATABRICKS_HOST', dbutils.secrets.get('default', 'databricks-host'))
DATABRICKS_TOKEN = os.getenv('DATABRICKS_TOKEN', dbutils.secrets.get('default', 'databricks-token'))
```

### **âœ… No Hardcoded Credentials**
- âŒ No workspace URLs in code
- âŒ No API tokens in files
- âŒ No sensitive information exposed
- âœ… All credentials via secrets management

## ğŸ“Š Expected Results

### **After Successful Import:**
- **26 executable notebooks** in your workspace
- **Organized folder structure** matching production layout
- **Ready-to-run cells** with proper Databricks formatting
- **Secure configuration** requiring only secrets setup

### **Execution Order:**
```
1. Setup: Configure secrets and Unity Catalog
2. Agents: Run 01 â†’ 02 â†’ 03 â†’ 04 â†’ 05 sequentially
3. RAG: Deploy vector search and testing
4. Flask: Deploy web applications
5. Monitor: Use dashboard setup notebooks
```

## âš ï¸ Troubleshooting

### **Import Fails**
- **Check File Format**: Ensure `.py` files have proper Databricks headers
- **Verify Permissions**: Confirm workspace import permissions
- **File Size**: Large files may need individual import

### **Execution Errors**
- **Secrets Missing**: Run secrets configuration first
- **Unity Catalog**: Verify catalog/schema permissions
- **Dependencies**: Check cluster has required libraries

### **Configuration Issues**
- **Model Access**: Confirm Foundation Model permissions
- **Vector Search**: Verify vector search endpoint exists
- **Compute**: Ensure appropriate cluster configuration

## ğŸ‰ Success Indicators

### **âœ… Import Success**
- [ ] All 26 notebooks imported without errors
- [ ] Folder structure preserved in workspace
- [ ] Notebooks show proper cell formatting
- [ ] No credential warnings in code

### **âœ… Execution Success**
- [ ] Secrets configured correctly
- [ ] Unity Catalog access working
- [ ] Agent pipeline runs successfully
- [ ] RAG system responds to queries
- [ ] Flask applications deploy properly

---

**ğŸ¯ Result**: Production-ready Network Fault Detection RCA System deployed in your Databricks workspace!

**ğŸ“ Support**: Refer to individual notebook documentation and error messages for specific issues.