# Databricks notebook source
# MAGIC %md
# MAGIC # 🚀 Lakeview Dashboard Setup - Network Fault Detection
# MAGIC
# MAGIC **Purpose**: Step-by-step creation of production monitoring dashboard
# MAGIC **Target**: Network operations team real-time visibility
# MAGIC **Duration**: 45-60 minutes total setup time
# MAGIC **Result**: Professional operations dashboard with 6 live widgets

# COMMAND ----------

# MAGIC %md
# MAGIC ## 📋 **PHASE 0: PRE-FLIGHT DATA VALIDATION**
# MAGIC
# MAGIC **Execute this cell first to confirm all required data is available**

# COMMAND ----------

# MAGIC %sql
# MAGIC -- STEP 1: First let's check the actual column names in each table
# MAGIC DESCRIBE network_fault_detection.processed_data.rca_reports_streaming;

# COMMAND ----------

# MAGIC %sql
# MAGIC -- STEP 2: Check severity classifications table schema
# MAGIC DESCRIBE network_fault_detection.processed_data.severity_classifications_streaming;

# COMMAND ----------

# MAGIC %sql
# MAGIC -- STEP 3: Check incident decisions table schema
# MAGIC DESCRIBE network_fault_detection.processed_data.incident_decisions_streaming;

# COMMAND ----------

# MAGIC %sql
# MAGIC -- STEP 4: Check network operations table schema
# MAGIC DESCRIBE network_fault_detection.processed_data.network_operations_streaming;

# COMMAND ----------

print("🔍 SCHEMA ANALYSIS COMPLETE!")
print("=" * 50)
print("📋 NEXT STEPS:")
print("1. Review the DESCRIBE results above to identify timestamp columns")
print("2. Common timestamp column names we expect:")
print("   - rca_timestamp (for RCA reports)")
print("   - severity_timestamp (for severity classifications)")
print("   - incident_timestamp (for incident decisions)")
print("   - operation_timestamp (for network operations)")
print("3. After confirming column names, proceed to the corrected data validation")

# COMMAND ----------

# MAGIC %sql
# MAGIC -- CORRECTED DATA VALIDATION QUERY
# MAGIC -- Using the actual column names from the schemas above
# MAGIC SELECT
# MAGIC     'rca_reports' as table_name,
# MAGIC     COUNT(*) as record_count,
# MAGIC     MAX(rca_timestamp) as latest_record,
# MAGIC     MIN(rca_timestamp) as earliest_record
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'severity_classifications',
# MAGIC     COUNT(*),
# MAGIC     MAX(severity_timestamp),
# MAGIC     MIN(severity_timestamp)
# MAGIC FROM network_fault_detection.processed_data.severity_classifications_streaming
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'incident_decisions',
# MAGIC     COUNT(*),
# MAGIC     MAX(incident_timestamp),
# MAGIC     MIN(incident_timestamp)
# MAGIC FROM network_fault_detection.processed_data.incident_decisions_streaming
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'network_operations',
# MAGIC     COUNT(*),
# MAGIC     MAX(operation_timestamp),
# MAGIC     MIN(operation_timestamp)
# MAGIC FROM network_fault_detection.processed_data.network_operations_streaming
# MAGIC
# MAGIC ORDER BY table_name;

# COMMAND ----------

print("✅ PRE-FLIGHT CHECK RESULTS:")
print("=" * 50)
print("Expected: 100+ records for each table")
print("Expected: Recent timestamps (within last few days)")
print()
print("📋 NEXT STEPS:")
print("1. If all tables show 100+ records → Proceed to Phase 1")
print("2. If any table shows 0 records → Run production pipeline first")
print("3. If timestamps are old → Check if pipeline is running")
print("4. If columns still don't match → Check SESSION_NOTES for exact schema")
print()
print("🎯 Ready to create Lakeview Dashboard!")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 🎯 **PHASE 1: WIDGET QUERIES PREPARATION**
# MAGIC
# MAGIC **Run each cell below to test and validate dashboard queries before creating widgets**

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 1: Incident Severity Distribution**
# MAGIC *This will become a bar chart showing P1/P2/P3 breakdown*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 1 QUERY: Incident Severity Distribution (Last 7 Days)
# MAGIC SELECT
# MAGIC     severity,
# MAGIC     COUNT(*) as incident_count,
# MAGIC     ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER (), 1) as percentage
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE rca_timestamp >= CURRENT_DATE() - INTERVAL 7 DAYS
# MAGIC GROUP BY severity
# MAGIC ORDER BY
# MAGIC     CASE severity
# MAGIC         WHEN 'P1' THEN 1
# MAGIC         WHEN 'P2' THEN 2
# MAGIC         WHEN 'P3' THEN 3
# MAGIC         ELSE 4
# MAGIC     END;

# COMMAND ----------

print("📊 Widget 1 Validation:")
print("Expected: P1, P2, P3 rows with counts and percentages")
print("Usage: Bar chart with severity on X-axis, incident_count on Y-axis")
print("Colors: P1=Red, P2=Orange, P3=Green")

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 2: 24-Hour Incident Timeline**
# MAGIC *This will become a line chart showing hourly incident trends*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 2 QUERY: 24-Hour Incident Timeline
# MAGIC SELECT
# MAGIC     DATE_TRUNC('hour', rca_timestamp) as hour,
# MAGIC     severity,
# MAGIC     COUNT(*) as incidents_per_hour
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE rca_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 24 HOURS
# MAGIC GROUP BY DATE_TRUNC('hour', rca_timestamp), severity
# MAGIC ORDER BY hour DESC;

# COMMAND ----------

print("📈 Widget 2 Validation:")
print("Expected: Hourly timestamps with severity breakdown")
print("Usage: Line chart with hour on X-axis, incidents_per_hour on Y-axis")
print("Group by: severity (creates multiple lines for P1/P2/P3)")

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 3: System Health Summary**
# MAGIC *This will become counter widgets showing key metrics*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 3 QUERY: System Health Metrics
# MAGIC SELECT
# MAGIC     'Total Incidents Today' as metric,
# MAGIC     COUNT(*) as value,
# MAGIC     'incidents' as unit
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE DATE(rca_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Critical (P1) Incidents',
# MAGIC     COUNT(*),
# MAGIC     'incidents'
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE DATE(rca_timestamp) = CURRENT_DATE() AND severity = 'P1'
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Average RCA Length',
# MAGIC     ROUND(AVG(LENGTH(rca_analysis))),
# MAGIC     'characters'
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE DATE(rca_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Pipeline Health',
# MAGIC     CASE WHEN COUNT(*) > 0 THEN 100 ELSE 0 END,
# MAGIC     'percent'
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE rca_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 1 HOUR;

# COMMAND ----------

print("📊 Widget 3 Validation:")
print("Expected: 4 rows with metric names and values")
print("Usage: Counter visualization with value column and metric labels")
print("Shows: Daily totals, P1 count, data quality, pipeline health")

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 4: Top Network Components**
# MAGIC *This will become a horizontal bar chart showing most problematic components*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 4 QUERY: Top Failing Network Components (7 Days)
# MAGIC SELECT
# MAGIC     CASE
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%ROUTER%' OR UPPER(log_content) LIKE '%ROUTER%' THEN 'Router'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%SWITCH%' OR UPPER(log_content) LIKE '%SWITCH%' THEN 'Switch'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%FIREWALL%' OR UPPER(log_content) LIKE '%FIREWALL%' THEN 'Firewall'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%SERVER%' OR UPPER(log_content) LIKE '%SERVER%' THEN 'Server'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%BGP%' OR UPPER(log_content) LIKE '%BGP%' THEN 'BGP Protocol'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%OSPF%' OR UPPER(log_content) LIKE '%OSPF%' THEN 'OSPF Protocol'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%INTERFACE%' OR UPPER(log_content) LIKE '%INTERFACE%' THEN 'Network Interface'
# MAGIC         WHEN UPPER(rca_analysis) LIKE '%CPU%' OR UPPER(log_content) LIKE '%CPU%' THEN 'CPU/Performance'
# MAGIC         ELSE 'Other'
# MAGIC     END as component_type,
# MAGIC     COUNT(*) as failure_count,
# MAGIC     ROUND(AVG(CASE WHEN severity = 'P1' THEN 1 ELSE 0 END) * 100, 1) as p1_percentage
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE rca_timestamp >= CURRENT_DATE() - INTERVAL 7 DAYS
# MAGIC GROUP BY component_type
# MAGIC HAVING COUNT(*) > 0
# MAGIC ORDER BY failure_count DESC
# MAGIC LIMIT 10;

# COMMAND ----------

print("🔧 Widget 4 Validation:")
print("Expected: Network component types with failure counts")
print("Usage: Horizontal bar chart with failure_count on X-axis")
print("Shows: Most problematic network components and P1 severity rates")

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 5: Agent Pipeline Performance**
# MAGIC *This will become a table showing processing status across all agents*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 5 QUERY: Agent Pipeline Processing Status
# MAGIC SELECT
# MAGIC     'Severity Classifications' as agent,
# MAGIC     COUNT(*) as records_processed,
# MAGIC     MAX(severity_timestamp) as last_update,
# MAGIC     CASE
# MAGIC         WHEN MAX(severity_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 2 HOURS THEN 'Healthy'
# MAGIC         WHEN MAX(severity_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 6 HOURS THEN 'Warning'
# MAGIC         ELSE 'Critical'
# MAGIC     END as status
# MAGIC FROM network_fault_detection.processed_data.severity_classifications_streaming
# MAGIC WHERE DATE(severity_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Incident Manager',
# MAGIC     COUNT(*),
# MAGIC     MAX(incident_timestamp),
# MAGIC     CASE
# MAGIC         WHEN MAX(incident_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 2 HOURS THEN 'Healthy'
# MAGIC         WHEN MAX(incident_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 6 HOURS THEN 'Warning'
# MAGIC         ELSE 'Critical'
# MAGIC     END
# MAGIC FROM network_fault_detection.processed_data.incident_decisions_streaming
# MAGIC WHERE DATE(incident_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Network Operations',
# MAGIC     COUNT(*),
# MAGIC     MAX(operation_timestamp),
# MAGIC     CASE
# MAGIC         WHEN MAX(operation_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 2 HOURS THEN 'Healthy'
# MAGIC         WHEN MAX(operation_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 6 HOURS THEN 'Warning'
# MAGIC         ELSE 'Critical'
# MAGIC     END
# MAGIC FROM network_fault_detection.processed_data.network_operations_streaming
# MAGIC WHERE DATE(operation_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'RCA Generator',
# MAGIC     COUNT(*),
# MAGIC     MAX(rca_timestamp),
# MAGIC     CASE
# MAGIC         WHEN MAX(rca_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 2 HOURS THEN 'Healthy'
# MAGIC         WHEN MAX(rca_timestamp) >= CURRENT_TIMESTAMP() - INTERVAL 6 HOURS THEN 'Warning'
# MAGIC         ELSE 'Critical'
# MAGIC     END
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE DATE(rca_timestamp) = CURRENT_DATE()
# MAGIC
# MAGIC ORDER BY records_processed DESC;

# COMMAND ----------

print("⚙️ Widget 5 Validation:")
print("Expected: 4 agents with processing counts and health status")
print("Usage: Table visualization showing agent performance")
print("Status: Healthy (< 2hrs), Warning (< 6hrs), Critical (> 6hrs)")

# COMMAND ----------

# MAGIC %md
# MAGIC ### **Widget 6: Data Quality Monitor**
# MAGIC *This will become a table showing data quality indicators*

# COMMAND ----------

# MAGIC %sql
# MAGIC -- WIDGET 6 QUERY: Data Quality Indicators
# MAGIC WITH quality_metrics AS (
# MAGIC     SELECT
# MAGIC         COUNT(*) as total_rca,
# MAGIC         COUNT(CASE WHEN LENGTH(rca_analysis) > 100 THEN 1 END) as quality_rca,
# MAGIC         AVG(LENGTH(rca_analysis)) as avg_length
# MAGIC     FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC     WHERE rca_timestamp >= CURRENT_DATE() - INTERVAL 7 DAYS
# MAGIC ),
# MAGIC pipeline_metrics AS (
# MAGIC     SELECT
# MAGIC         COUNT(DISTINCT r.incident_id) as rca_incidents,
# MAGIC         COUNT(DISTINCT s.incident_id) as severity_incidents
# MAGIC     FROM network_fault_detection.processed_data.rca_reports_streaming r
# MAGIC     FULL OUTER JOIN network_fault_detection.processed_data.severity_classifications_streaming s
# MAGIC         ON r.incident_id = s.incident_id
# MAGIC     WHERE r.rca_timestamp >= CURRENT_DATE() - INTERVAL 1 DAY
# MAGIC        OR s.severity_timestamp >= CURRENT_DATE() - INTERVAL 1 DAY
# MAGIC )
# MAGIC
# MAGIC SELECT
# MAGIC     'Quality RCA Reports (7d)' as metric,
# MAGIC     CONCAT(quality_rca, ' / ', total_rca) as value,
# MAGIC     CONCAT(ROUND(quality_rca * 100.0 / NULLIF(total_rca, 0), 1), '%') as percentage
# MAGIC FROM quality_metrics
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Average Content Length',
# MAGIC     CONCAT(ROUND(avg_length), ' chars'),
# MAGIC     CASE WHEN avg_length > 200 THEN 'Excellent'
# MAGIC          WHEN avg_length > 100 THEN 'Good'
# MAGIC          ELSE 'Poor' END
# MAGIC FROM quality_metrics
# MAGIC
# MAGIC UNION ALL
# MAGIC
# MAGIC SELECT
# MAGIC     'Pipeline Completeness (24h)',
# MAGIC     CONCAT(rca_incidents, ' / ', severity_incidents),
# MAGIC     CONCAT(ROUND(rca_incidents * 100.0 / NULLIF(severity_incidents, 0), 1), '%')
# MAGIC FROM pipeline_metrics;

# COMMAND ----------

print("🔍 Widget 6 Validation:")
print("Expected: 3 metrics showing data quality indicators")
print("Usage: Table showing quality percentages and assessments")
print("Monitors: RCA content quality, average length, pipeline completeness")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 🎯 **PHASE 2: DASHBOARD CREATION INSTRUCTIONS**
# MAGIC
# MAGIC **Now that all queries are validated, follow these steps to create the actual Lakeview Dashboard**

# COMMAND ----------

print("🚀 LAKEVIEW DASHBOARD CREATION STEPS")
print("=" * 60)
print()
print("📍 STEP 1: ACCESS LAKEVIEW")
print("   1. Go to Databricks workspace")
print("   2. Click 'SQL' in left sidebar")
print("   3. Click 'Dashboards'")
print("   4. Click 'Create Dashboard' (blue button)")
print()
print("📋 STEP 2: DASHBOARD SETUP")
print("   Dashboard Name: 'Network Fault Detection Operations'")
print("   Description: 'Real-time monitoring of network incidents and system health'")
print("   Click 'Create Dashboard'")
print()
print("🎯 STEP 3: CREATE WIDGETS")
print("   For each widget below:")
print("   - Click 'Add' → 'Visualization'")
print("   - Copy the exact query from the cells above")
print("   - Configure visualization type as specified")
print("   - Save widget")
print()
print("📊 WIDGET CONFIGURATION GUIDE:")

# COMMAND ----------

widget_configs = [
    {
        "name": "Widget 1: Incident Severity Distribution",
        "query_cell": "Cell above with 'WIDGET 1 QUERY'",
        "viz_type": "Bar Chart",
        "x_axis": "severity",
        "y_axis": "incident_count",
        "colors": "P1=Red, P2=Orange, P3=Green"
    },
    {
        "name": "Widget 2: 24-Hour Incident Timeline",
        "query_cell": "Cell above with 'WIDGET 2 QUERY'",
        "viz_type": "Line Chart",
        "x_axis": "hour",
        "y_axis": "incidents_per_hour",
        "group_by": "severity"
    },
    {
        "name": "Widget 3: System Health Summary",
        "query_cell": "Cell above with 'WIDGET 3 QUERY'",
        "viz_type": "Counter",
        "value_column": "value",
        "label_column": "metric"
    },
    {
        "name": "Widget 4: Top Network Components",
        "query_cell": "Cell above with 'WIDGET 4 QUERY'",
        "viz_type": "Horizontal Bar Chart",
        "x_axis": "failure_count",
        "y_axis": "component_type"
    },
    {
        "name": "Widget 5: Agent Pipeline Performance",
        "query_cell": "Cell above with 'WIDGET 5 QUERY'",
        "viz_type": "Table",
        "note": "Shows all columns as table"
    },
    {
        "name": "Widget 6: Data Quality Monitor",
        "query_cell": "Cell above with 'WIDGET 6 QUERY'",
        "viz_type": "Table",
        "note": "Shows quality metrics as table"
    }
]

for i, widget in enumerate(widget_configs, 1):
    print(f"\n🎯 {widget['name']}")
    print(f"   Query Source: {widget['query_cell']}")
    print(f"   Visualization: {widget['viz_type']}")
    if 'x_axis' in widget:
        print(f"   X-axis: {widget['x_axis']}")
    if 'y_axis' in widget:
        print(f"   Y-axis: {widget['y_axis']}")
    if 'colors' in widget:
        print(f"   Colors: {widget['colors']}")
    if 'group_by' in widget:
        print(f"   Group by: {widget['group_by']}")
    if 'value_column' in widget:
        print(f"   Value: {widget['value_column']}")
    if 'label_column' in widget:
        print(f"   Label: {widget['label_column']}")
    if 'note' in widget:
        print(f"   Note: {widget['note']}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ⚙️ **PHASE 3: DASHBOARD CONFIGURATION**

# COMMAND ----------

print("⚙️ DASHBOARD CONFIGURATION STEPS")
print("=" * 50)
print()
print("🔄 AUTO-REFRESH SETUP:")
print("   1. Click Dashboard Settings (gear icon)")
print("   2. Set Auto Refresh: 5 minutes")
print("   3. Click Save")
print()
print("📐 LAYOUT ARRANGEMENT:")
print("   Recommended layout:")
print("   ┌─────────────────────┬───────────────────────┐")
print("   │ System Health       │ Data Quality Monitor  │")
print("   │ (Counters)         │ (Table)               │")
print("   ├─────────────────────┼───────────────────────┤")
print("   │ Severity Distrib.   │ 24-Hour Timeline      │")
print("   │ (Bar Chart)        │ (Line Chart)          │")
print("   ├─────────────────────┼───────────────────────┤")
print("   │ Top Components      │ Pipeline Performance  │")
print("   │ (Horizontal Bar)   │ (Table)               │")
print("   └─────────────────────┴───────────────────────┘")
print()
print("👥 SHARING SETUP:")
print("   1. Click 'Share' button")
print("   2. Add network operations team")
print("   3. Set permission: 'Can Run'")
print("   4. Click Save")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 🎯 **PHASE 4: OPTIONAL ALERTS SETUP**

# COMMAND ----------

# MAGIC %sql
# MAGIC -- OPTIONAL ALERT QUERY: P1 Incident Threshold
# MAGIC -- Use this to create an alert for too many P1 incidents
# MAGIC SELECT COUNT(*) as p1_count
# MAGIC FROM network_fault_detection.processed_data.rca_reports_streaming
# MAGIC WHERE severity = 'P1'
# MAGIC   AND rca_timestamp >= CURRENT_TIMESTAMP() - INTERVAL 1 HOUR;

# COMMAND ----------

print("🚨 OPTIONAL ALERT SETUP:")
print("=" * 40)
print()
print("📧 P1 Incident Alert:")
print("   1. In dashboard, click 'Add' → 'Alert'")
print("   2. Alert Name: 'P1 Incident Threshold'")
print("   3. Use query from cell above")
print("   4. Condition: p1_count > 2")
print("   5. Set email/Slack destination")
print("   6. Click Save")
print()
print("⏰ Additional Alert Ideas:")
print("   - Pipeline health: No new data in 2+ hours")
print("   - Data quality: Quality percentage < 70%")
print("   - Agent failures: Any agent showing 'Critical' status")

# COMMAND ----------

# MAGIC %md
# MAGIC ## ✅ **PHASE 5: VALIDATION AND TESTING**

# COMMAND ----------

print("✅ DASHBOARD VALIDATION CHECKLIST")
print("=" * 50)
print()
print("🔍 FUNCTIONALITY TESTS:")
print("   □ All 6 widgets display data correctly")
print("   □ Auto-refresh works (wait 5 minutes)")
print("   □ Shared access works (test with team member)")
print("   □ Mobile/tablet view is readable")
print()
print("📊 DATA VALIDATION:")
print("   □ Widget 1: Shows P1/P2/P3 distribution")
print("   □ Widget 2: Shows hourly trends")
print("   □ Widget 3: Shows today's metrics")
print("   □ Widget 4: Shows network components")
print("   □ Widget 5: Shows all 4 agents")
print("   □ Widget 6: Shows quality indicators")
print()
print("⚙️ CONFIGURATION CHECKS:")
print("   □ 5-minute auto-refresh enabled")
print("   □ Professional layout applied")
print("   □ Team members have access")
print("   □ Alert configured (if desired)")
print()
print("🎯 EXPECTED BUSINESS VALUE:")
print("   ✅ Real-time network health visibility")
print("   ✅ Proactive incident trend monitoring")
print("   ✅ Agent pipeline health tracking")
print("   ✅ Data quality assurance")
print("   ✅ Component failure pattern analysis")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 🚀 **PHASE 6: DASHBOARD URL AND NEXT STEPS**

# COMMAND ----------

print("🔗 DASHBOARD ACCESS AND NEXT STEPS")
print("=" * 50)
print()
print("📱 DASHBOARD ACCESS:")
print("   Your dashboard will be available at:")
print("   https://[your-workspace].cloud.databricks.com/sql/dashboards/[dashboard-id]")
print()
print("📋 TEAM ONBOARDING:")
print("   1. Share dashboard URL with operations team")
print("   2. Provide 5-minute demo of key widgets")
print("   3. Document escalation procedures for alerts")
print("   4. Schedule weekly review of dashboard effectiveness")
print()
print("🔄 CONTINUOUS IMPROVEMENT:")
print("   Week 1: Gather team feedback on widget usefulness")
print("   Week 2: Add custom widgets based on specific needs")
print("   Week 3: Integrate with incident response procedures")
print("   Month 1: Create executive summary dashboard variant")
print()
print("📈 SUCCESS METRICS:")
print("   - Team uses dashboard daily for operations")
print("   - Incidents detected faster through trend monitoring")
print("   - Pipeline issues identified proactively")
print("   - Data quality maintained above 80%")
print()
print("🎯 TOTAL SETUP TIME: 45-60 minutes")
print("💰 ONGOING COST: $0 (included in Databricks workspace)")
print("🚀 BUSINESS VALUE: Immediate operational visibility")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 📞 **SUPPORT AND TROUBLESHOOTING**

# COMMAND ----------

print("🔧 COMMON ISSUES AND SOLUTIONS")
print("=" * 50)
print()
print("❌ ISSUE: No data in widgets")
print("   ✅ SOLUTION: Check if production pipeline is running")
print("   📋 ACTION: Run data validation queries in Phase 0")
print()
print("❌ ISSUE: Widgets show errors")
print("   ✅ SOLUTION: Verify Unity Catalog permissions")
print("   📋 ACTION: Contact admin for table access")
print()
print("❌ ISSUE: Auto-refresh not working")
print("   ✅ SOLUTION: Re-configure dashboard settings")
print("   📋 ACTION: Dashboard Settings → Auto Refresh → Save")
print()
print("❌ ISSUE: Sharing doesn't work")
print("   ✅ SOLUTION: Check user permissions")
print("   📋 ACTION: Verify users have workspace access")
print()
print("📞 ESCALATION PATH:")
print("   1. Technical issues: Check SESSION_NOTES_CLEAN.md")
print("   2. Data issues: Verify production pipeline status")
print("   3. Permission issues: Contact Databricks admin")
print("   4. Feature requests: Document for next enhancement cycle")

# COMMAND ----------

print("🎉 LAKEVIEW DASHBOARD SETUP COMPLETE!")
print("=" * 60)
print()
print("✅ ACHIEVEMENT UNLOCKED:")
print("   - Professional operations dashboard created")
print("   - Real-time network monitoring operational")
print("   - Team visibility into system health")
print("   - Proactive incident trend analysis")
print()
print("🚀 NEXT PHASE:")
print("   Consider building Databricks App for interactive RAG features")
print("   Reference: SESSION_NOTES_CLEAN.md → Databricks Apps section")
print()
print("📊 DASHBOARD SUMMARY:")
print("   • 6 live widgets with 5-minute auto-refresh")
print("   • Incident trends and severity monitoring")
print("   • Agent pipeline health tracking")
print("   • Network component failure analysis")
print("   • Data quality assurance metrics")
print("   • Professional sharing and mobile access")
print()
print("🎯 BUSINESS IMPACT: Immediate operational excellence!")