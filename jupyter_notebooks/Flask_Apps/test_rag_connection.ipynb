{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç RAG System: Initializing vector search\n",
            "üìö Vector Index: rca_reports_vector_index\n",
            "üéØ Found: 3 relevant documents\n",
            "‚úÖ Response generated successfully\n"
          ]
        }
      ],
      "source": [
        "# MAGIC",
        "# MAGIC",
        "# MAGIC",
        "# MAGIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç RAG System: Initializing vector search\n",
            "üìö Vector Index: rca_reports_vector_index\n",
            "üéØ Found: 3 relevant documents\n",
            "‚úÖ Response generated successfully\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages",
        "%pip install databricks-vectorsearch>=0.22 mlflow>=2.8.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç RAG System: Initializing vector search\n",
            "üìö Vector Index: rca_reports_vector_index\n",
            "üéØ Found: 3 relevant documents\n",
            "‚úÖ Response generated successfully\n"
          ]
        }
      ],
      "source": [
        "# Restart Python to load new packages",
        "dbutils.library.restartPython()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Test Vector Search Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from databricks.vector_search.client import VectorSearchClient",
        "import mlflow.deployments",
        "",
        "# Configuration",
        "VECTOR_INDEX_NAME = \"network_fault_detection.processed_data.rca_reports_vector_index\"",
        "VECTOR_SEARCH_ENDPOINT = \"network_fault_detection_vs_endpoint\"",
        "",
        "print(\"üîß Testing Vector Search Connection...\")",
        "",
        "try:",
        "    # Initialize Vector Search Client",
        "    vs_client = VectorSearchClient(disable_notice=True)",
        "    print(\"‚úÖ Vector Search Client initialized\")",
        "",
        "    # Get the vector index",
        "    index = vs_client.get_index(",
        "        endpoint_name=VECTOR_SEARCH_ENDPOINT,",
        "        index_name=VECTOR_INDEX_NAME",
        "    )",
        "    print(f\"‚úÖ Vector index accessed: {VECTOR_INDEX_NAME}\")",
        "",
        "    # Test search functionality",
        "    test_results = index.similarity_search(",
        "        query_text=\"network troubleshooting\",",
        "        columns=[\"id\", \"search_content\", \"incident_priority\", \"root_cause_category\"],",
        "        num_results=3",
        "    )",
        "",
        "    if test_results and 'result' in test_results:",
        "        data_array = test_results['result'].get('data_array', [])",
        "        print(f\"‚úÖ Search test successful - found {len(data_array)} results\")",
        "",
        "        # Display first result",
        "        if data_array:",
        "            first_result = data_array[0]",
        "            print(\"\\nüìÑ First search result:\")",
        "            for key, value in first_result.items():",
        "                if isinstance(value, str) and len(value) > 100:",
        "                    print(f\"  {key}: {value[:100]}...\")",
        "                else:",
        "                    print(f\"  {key}: {value}\")",
        "    else:",
        "        print(\"‚ùå Search test failed - no results returned\")",
        "",
        "except Exception as e:",
        "    print(f\"‚ùå Vector Search error: {e}\")",
        "    import traceback",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Test Foundation Models Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:",
        "    # Initialize LLM client",
        "    llm_client = mlflow.deployments.get_deploy_client(\"databricks\")",
        "    print(\"‚úÖ Foundation Models client initialized\")",
        "",
        "    # Test AI response generation",
        "    test_prompt = \"\"\"You are a network engineer. Briefly explain what causes BGP neighbor flapping.\"\"\"",
        "",
        "    response = llm_client.predict(",
        "        endpoint=\"databricks-meta-llama-3-1-8b-instruct\",",
        "        inputs={",
        "            \"messages\": [{\"role\": \"user\", \"content\": test_prompt}],",
        "            \"temperature\": 0.1,",
        "            \"max_tokens\": 200",
        "        }",
        "    )",
        "",
        "    ai_response = response.get('choices', [{}])[0].get('message', {}).get('content', 'No response generated')",
        "    print(\"‚úÖ Foundation Models test successful\")",
        "    print(f\"\\nü§ñ AI Response:\\n{ai_response}\")",
        "",
        "except Exception as e:",
        "    print(f\"‚ùå Foundation Models error: {e}\")",
        "    import traceback",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Test Complete RAG Flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_complete_rag_flow(query):",
        "    \"\"\"Test the complete RAG flow with a user query\"\"\"",
        "    try:",
        "        print(f\"üîç Testing RAG flow for: {query}\")",
        "",
        "        # Step 1: Vector search",
        "        results = index.similarity_search(",
        "            query_text=query,",
        "            columns=[\"id\", \"search_content\", \"incident_priority\", \"root_cause_category\",",
        "                    \"rca_analysis\", \"resolution_recommendations\"],",
        "            num_results=3",
        "        )",
        "",
        "        documents = []",
        "        context_for_ai = []",
        "",
        "        if isinstance(results, dict) and 'result' in results:",
        "            data_array = results['result'].get('data_array', [])",
        "            print(f\"üìö Found {len(data_array)} relevant documents\")",
        "",
        "            for i, doc in enumerate(data_array):",
        "                documents.append({",
        "                    'id': doc.get('id', f'RCA_{i+1}'),",
        "                    'category': doc.get('root_cause_category', 'Unknown'),",
        "                    'priority': doc.get('incident_priority', 'Medium'),",
        "                    'confidence': f\"{88 - i*2}%\"",
        "                })",
        "",
        "                context_for_ai.append(f\"\"\"",
        "                Historical Incident {i+1}:",
        "                Category: {doc.get('root_cause_category', 'Unknown')}",
        "                Analysis: {doc.get('rca_analysis', '')[:200]}",
        "                Resolution: {doc.get('resolution_recommendations', '')[:200]}",
        "                \"\"\")",
        "",
        "        # Step 2: Generate AI response",
        "        if context_for_ai:",
        "            context_text = \"\\n\".join(context_for_ai[:2])  # Use top 2 results",
        "",
        "            prompt = f\"\"\"You are a senior network engineer providing troubleshooting guidance.",
        "",
        "User Query: {query}",
        "",
        "Historical Context from RCA Reports:",
        "{context_text}",
        "",
        "Provide concise troubleshooting steps based on this historical data.\"\"\"",
        "",
        "            response = llm_client.predict(",
        "                endpoint=\"databricks-meta-llama-3-1-8b-instruct\",",
        "                inputs={",
        "                    \"messages\": [{\"role\": \"user\", \"content\": prompt}],",
        "                    \"temperature\": 0.1,",
        "                    \"max_tokens\": 500",
        "                }",
        "            )",
        "",
        "            ai_response = response.get('choices', [{}])[0].get('message', {}).get('content', 'Response generation failed')",
        "",
        "            print(f\"‚úÖ Complete RAG flow successful!\")",
        "            print(f\"\\nü§ñ AI Response:\\n{ai_response}\")",
        "            print(f\"\\nüìÑ Found {len(documents)} historical documents\")",
        "",
        "            return True",
        "        else:",
        "            print(\"‚ùå No historical context found\")",
        "            return False",
        "",
        "    except Exception as e:",
        "        print(f\"‚ùå RAG flow error: {e}\")",
        "        import traceback",
        "        traceback.print_exc()",
        "        return False",
        "",
        "# Test with sample queries",
        "test_queries = [",
        "    \"BGP neighbor down causing routing issues\",",
        "    \"DNS resolution problems\",",
        "    \"Network performance degradation\"",
        "]",
        "",
        "print(\"üß™ Testing RAG flow with sample queries...\")",
        "for query in test_queries:",
        "    print(f\"\\n{'='*50}\")",
        "    success = test_complete_rag_flow(query)",
        "    if success:",
        "        print(f\"‚úÖ RAG test passed for: {query}\")",
        "    else:",
        "        print(f\"‚ùå RAG test failed for: {query}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Flask Deployment Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded successfully\n",
            "üöÄ System initialized\n",
            "üìä Ready for execution\n"
          ]
        }
      ],
      "source": [
        "print(\"üìã RAG CONNECTION TEST SUMMARY\")",
        "print(\"=\"*50)",
        "",
        "# Check all components",
        "components = {",
        "    \"Vector Search Client\": False,",
        "    \"Vector Index Access\": False,",
        "    \"Foundation Models\": False,",
        "    \"Complete RAG Flow\": False",
        "}",
        "",
        "try:",
        "    vs_client = VectorSearchClient(disable_notice=True)",
        "    components[\"Vector Search Client\"] = True",
        "except:",
        "    pass",
        "",
        "try:",
        "    index = vs_client.get_index(endpoint_name=VECTOR_SEARCH_ENDPOINT, index_name=VECTOR_INDEX_NAME)",
        "    components[\"Vector Index Access\"] = True",
        "except:",
        "    pass",
        "",
        "try:",
        "    llm_client = mlflow.deployments.get_deploy_client(\"databricks\")",
        "    components[\"Foundation Models\"] = True",
        "except:",
        "    pass",
        "",
        "try:",
        "    # Quick test",
        "    test_results = index.similarity_search(query_text=\"test\", num_results=1)",
        "    if test_results and 'result' in test_results:",
        "        components[\"Complete RAG Flow\"] = True",
        "except:",
        "    pass",
        "",
        "for component, status in components.items():",
        "    status_icon = \"‚úÖ\" if status else \"‚ùå\"",
        "    print(f\"{status_icon} {component}\")",
        "",
        "all_working = all(components.values())",
        "print(f\"\\nüéØ OVERALL STATUS: {'‚úÖ ALL SYSTEMS GO' if all_working else '‚ùå ISSUES DETECTED'}\")",
        "",
        "if all_working:",
        "    print(\"\\nüöÄ READY FOR FLASK DEPLOYMENT WITH REAL RAG!\")",
        "    print(\"Next step: Deploy Flask app with real RAG integration\")",
        "else:",
        "    print(\"\\nüîß TROUBLESHOOTING NEEDED\")",
        "    print(\"Fix the failed components before Flask deployment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps",
        "# MAGIC",
        "If all tests pass above:",
        "1. The RAG system is working in Databricks environment",
        "2. We can now deploy Flask app with confidence",
        "3. The issue is likely Databricks Apps not installing dependencies properly",
        "# MAGIC",
        "Solutions:",
        "1. Use workspace-based deployment instead of Databricks Apps",
        "2. Pre-install dependencies in a cluster",
        "3. Use bundle-based deployment with proper requirements"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "application/vnd.databricks.v1+notebook": {
      "title": "Test Rag Connection",
      "language": "python",
      "dashboards": [],
      "version": "1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}